import json
import csv
from typing import List, Dict, Union
from datetime import datetime
import argparse

def parse_key_value_sequence(seq: List, value_idx: int):
    """
    è§£æâ€œé”®åºå·åˆ—è¡¨+å€¼â€çš„äº¤æ›¿åºåˆ—ï¼Œè¿”å›æ ‡å‡†é”®å€¼å­—å…¸
    :param seq: è¾“å…¥çš„äº¤æ›¿åºåˆ—ï¼ˆå¦‚[["_1":2], "root", ["_3":4], "data"]ï¼‰
    :return: æ ‡å‡†é”®å€¼å­—å…¸
    """

    if isinstance(seq[value_idx], str):
        return seq[value_idx]
    if isinstance(seq[value_idx], list):
        return seq[value_idx]
    if isinstance(seq[value_idx], dict):
        result = {}
        for _k,v in seq[value_idx].items():
            if _k.startswith('_'):
                result[seq[int(_k[1:])]] = parse_key_value_sequence(seq, v)
            else:
                continue
        return result
    else:
        return ""

def extract_image_info_from_parsed(parsed_data: Dict, seq: List) -> List[Dict[str, str]]:
    """
    ä»è§£æåçš„æ ‡å‡†å­—å…¸ä¸­æå–é•œåƒidã€created_atã€updated_at
    :param parsed_data: ç»parse_key_value_sequenceå¤„ç†åçš„æ ‡å‡†å­—å…¸
    :return: é•œåƒä¿¡æ¯åˆ—è¡¨
    """
    image_list = []

    # 1. å®šä½åˆ°searchResultsï¼ˆé”®åºå·_13å¯¹åº”çš„å€¼ï¼‰
    if "routes/_layout.search" not in parsed_data:
        raise KeyError("âŒ æœªæ‰¾åˆ°routes/_layout.searchï¼Œæ•°æ®ç»“æ„å¼‚å¸¸")
    search_results = parsed_data["routes/_layout.search"]


    results = search_results["data"]["searchResults"]["results"]
    assert isinstance(results, list), "results ç±»å‹é”™è¯¯"
    print(results)

    # 3. éå†æ¯ä¸ªé•œåƒæ•°æ®å—ï¼Œæå–ç›®æ ‡å­—æ®µ
    for img_idx, img_data_idx in enumerate(results, 1):
        assert isinstance(seq[img_data_idx], dict)
        img_data = {}
        for _k, v in seq[img_data_idx].items():
            k = seq[int(_k[1:])]
            if k in ('id', 'name', 'created_at', 'updated_at', 'short_description', 'pull_count', 'star_count'):
                img_data[k] = seq[v]

        # æå–ç›®æ ‡å­—æ®µï¼ˆåŸºäºé”®å€¼åºå·æ˜ å°„ï¼‰
        # - idï¼šé”®åºå·_22æˆ–_24å¯¹åº”çš„å€¼ï¼ˆæ‰€æœ‰é•œåƒå‡å«è¿™ä¸¤ä¸ªé”®ï¼Œå€¼ç›¸åŒï¼‰
        img_id = img_data.get("id", img_data.get("name", "æœªè·å–åˆ°id"))
        # - created_atï¼šé”®åºå·_28å¯¹åº”çš„å€¼
        created_at = img_data.get("created_at", "æœªè·å–åˆ°åˆ›å»ºæ—¶é—´")
        # - updated_atï¼šé”®åºå·_32å¯¹åº”çš„å€¼
        updated_at = img_data.get("updated_at", "æœªè·å–åˆ°æ›´æ–°æ—¶é—´")
        
        # è½¬æ¢æ—¶é—´æ ¼å¼ï¼ˆISO 8601â†’æœ¬åœ°æ—¶é—´ï¼‰
        def convert_time(iso_time: str) -> str:
            if iso_time.startswith("20") and "T" in iso_time:
                try:
                    return datetime.fromisoformat(iso_time.replace("Z", "+00:00")).astimezone().strftime("%Y-%m-%d %H:%M:%S")
                except:
                    return iso_time
            return iso_time

        img_data.update({
            "é•œåƒåºå·": img_idx,
            "id": img_id,
            "created_at_æœ¬åœ°": convert_time(created_at),
            "updated_at_æœ¬åœ°": convert_time(updated_at),
            "pull_count": img_data.get('pull_count', 0),
            "star_count": img_data.get('star_count', 0)
        })
        image_list.append(img_data)
    
    print(f"âœ… æˆåŠŸæå–{len(image_list)}ä¸ªé•œåƒä¿¡æ¯")
    return image_list

def load_and_parse_raw_file(input_path: str):
    """
    åŠ è½½åŸå§‹é™„ä»¶æ–‡ä»¶å¹¶è§£æä¸ºæ ‡å‡†é”®å€¼å­—å…¸
    :param input_path: åŸå§‹æ–‡ä»¶è·¯å¾„ï¼ˆllama.cpp.search.txtï¼‰
    :return: æ ‡å‡†é”®å€¼å­—å…¸
    """
    # 1. è¯»å–åŸå§‹æ–‡ä»¶
    try:
        with open(input_path, "r", encoding="utf-8") as f:
            # å¤„ç†é™„ä»¶ä¸­å¯èƒ½çš„æ ¼å¼é—®é¢˜ï¼ˆå¦‚å¤šä½™çš„ç©ºæ ¼ã€æ³¨é‡Šï¼‰
            raw_content = f.read().strip().replace("<! [CDATA[", "").replace("]]>", "")
            raw_seq = json.loads(raw_content)
        print(f"âœ… æˆåŠŸåŠ è½½åŸå§‹æ–‡ä»¶ï¼š{input_path}")
    except FileNotFoundError:
        raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ°æ–‡ä»¶ï¼š{input_path}ï¼Œè¯·æ£€æŸ¥è·¯å¾„")
    except json.JSONDecodeError as e:
        raise json.JSONDecodeError(f"âŒ åŸå§‹æ–‡ä»¶JSONè§£æå¤±è´¥ï¼š{str(e)}", doc=input_path, pos=e.pos)
    
    # 2. è§£æâ€œé”®åºå·+å€¼â€åºåˆ—ä¸ºæ ‡å‡†å­—å…¸
    try:
        parsed_dict = parse_key_value_sequence(raw_seq, 0)
        print("âœ… æˆåŠŸè§£æé”®å€¼åºå·åºåˆ—ä¸ºæ ‡å‡†å­—å…¸")
    except Exception as e:
        raise RuntimeError(f"âŒ è§£æé”®å€¼åºåˆ—å¤±è´¥ï¼š{str(e)}")
    
    return parsed_dict, raw_seq

def save_image_info(image_info: List[Dict[str, str]], output_prefix: str = "llama_cpp_images") -> None:
    """
    ä¿å­˜é•œåƒä¿¡æ¯ä¸ºJSONå’ŒCSVæ ¼å¼
    :param image_info: é•œåƒä¿¡æ¯åˆ—è¡¨
    :param output_prefix: è¾“å‡ºæ–‡ä»¶å‰ç¼€
    """
    # 1. ä¿å­˜JSON
    json_path = f"{output_prefix}_info.json"
    try:
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(image_info, f, ensure_ascii=False, indent=4)
        print(f"âœ… JSONæ–‡ä»¶å·²ä¿å­˜ï¼š{json_path}")
    except Exception as e:
        print(f"âŒ ä¿å­˜JSONå¤±è´¥ï¼š{str(e)}")
    
    # 2. ä¿å­˜CSV
    csv_path = f"{output_prefix}_info.csv"
    headers = ["é•œåƒåºå·", "id", "created_at_æœ¬åœ°", "updated_at_æœ¬åœ°", 'name', 'created_at', 'updated_at', 'short_description', 'pull_count', 'star_count']
    try:
        with open(csv_path, "w", encoding="utf-8-sig", newline="") as f:
            writer = csv.DictWriter(f, fieldnames=headers)
            writer.writeheader()
            writer.writerows(image_info)
        print(f"âœ… CSVæ–‡ä»¶å·²ä¿å­˜ï¼š{csv_path}")
    except Exception as e:
        print(f"âŒ ä¿å­˜CSVå¤±è´¥ï¼š{str(e)}")

def print_console_table(image_info: List[Dict[str, str]]) -> None:
    """
    æ§åˆ¶å°æ ¼å¼åŒ–æ‰“å°é•œåƒä¿¡æ¯
    """
    if not image_info:
        print("âŒ æ— é•œåƒä¿¡æ¯å¯æ‰“å°")
        return
    
    # å®šä¹‰åˆ—å®½ï¼ˆé€‚é…æœ€é•¿å­—æ®µï¼‰
    col_widths = {
        "é•œåƒåºå·": 8,
        "id": 40,
        "created_at_æœ¬åœ°": 20,
        "updated_at_æœ¬åœ°": 20
    }
    
    # æ‰“å°è¡¨å¤´
    print("\n" + "="*90)
    print(f"llama.cppé•œåƒä¿¡æ¯ï¼ˆå…±{len(image_info)}ä¸ªï¼‰")
    print("="*90)
    header = (f"{'é•œåƒåºå·':<{col_widths['é•œåƒåºå·']}}"
              f"{'id':<{col_widths['id']}}"
              f"{'åˆ›å»ºæ—¶é—´ï¼ˆæœ¬åœ°ï¼‰':<{col_widths['created_at_æœ¬åœ°']}}"
              f"{'æ›´æ–°æ—¶é—´ï¼ˆæœ¬åœ°ï¼‰':<{col_widths['updated_at_æœ¬åœ°']}}")
    print(header)
    print("-"*90)
    
    # æ‰“å°æ•°æ®
    for info in image_info:
        row = (f"{info['é•œåƒåºå·']:<{col_widths['é•œåƒåºå·']}}"
               f"{info['id']:<{col_widths['id']}}"
               f"{info['created_at_æœ¬åœ°']:<{col_widths['created_at_æœ¬åœ°']}}"
               f"{info['updated_at_æœ¬åœ°']:<{col_widths['updated_at_æœ¬åœ°']}}")
        print(row)

if __name__ == "__main__":
    # é…ç½®å‚æ•°
    parser = argparse.ArgumentParser()
    parser.add_argument("input_path", type=str, help="åŸå§‹æ–‡ä»¶çš„è·¯å¾„")
    args = parser.parse_args()
    INPUT_PATH =  args.input_path # åŸå§‹é™„ä»¶è·¯å¾„
    OUTPUT_PREFIX = "images"   # è¾“å‡ºæ–‡ä»¶å‰ç¼€
    
    try:
        # æ­¥éª¤1ï¼šåŠ è½½å¹¶è§£æåŸå§‹é”®å€¼åºå·åºåˆ—
        parsed_data, raw_seq = load_and_parse_raw_file(INPUT_PATH)
        print(json.dumps(parsed_data))
        # æ­¥éª¤2ï¼šæå–é•œåƒç›®æ ‡ä¿¡æ¯
        image_info = extract_image_info_from_parsed(parsed_data, raw_seq)
        
        # æ­¥éª¤3ï¼šè¾“å‡ºç»“æœï¼ˆæ§åˆ¶å°+æ–‡ä»¶ï¼‰
        print_console_table(image_info)
        save_image_info(image_info, OUTPUT_PREFIX)
        
        print("\nğŸ‰ æ‰€æœ‰æ“ä½œå®Œæˆï¼")
    
    except Exception as e:
        print(f"\nâŒ ç¨‹åºç»ˆæ­¢ï¼š{str(e)}")
